{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "processed-modification",
   "metadata": {},
   "source": [
    "<img src = 'fotos/logo_dani.jpeg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elegant-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX \n",
    "import itertools\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affecting-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(real, predicted):\n",
    "    return np.sqrt(((real - predicted) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-astronomy",
   "metadata": {},
   "source": [
    "## Ficheros y rutas de entrada/salida "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "detected-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_in = '../../datos/datos_desarrollo'\n",
    "file1_in = 'consumo_final.csv'\n",
    "dir_out = dir_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-cursor",
   "metadata": {},
   "source": [
    "## Carga de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "elder-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consumo = pd.read_csv(os.path.join(dir_in, file1_in), sep = ';')\n",
    "df_consumo.columns = [columna.lower() for columna in df_consumo.columns]\n",
    "df_consumo.rename(columns = {'fecha_inicio': 'mes_inicio_temp', 'fecha_fin': 'mes_fin_temp'}, inplace = True)\n",
    "df_consumo.date = pd.to_datetime(df_consumo.date, format = '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "communist-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "precio_model = df_consumo[['ccaa', 'producto', 'volumen_miles_de_kg', 'valor_miles_de_€', 'precio_medio_kg', 'date']]\n",
    "cmpl_model_dict = {product: {comunidad: precio_model[(precio_model.producto.eq(product))&\n",
    "                                                      (precio_model.ccaa.eq(comunidad))].drop(['producto', 'ccaa'], axis = 1)\n",
    "                              for comunidad in precio_model.ccaa.unique()} for product in precio_model.producto.unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daily-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prueba = df_consumo[(df_consumo.ccaa.isin(['Andalucia', 'Aragon'])) & (df_consumo.producto.isin(['Patatas', 'Mango']))]\n",
    "prueba_model = df_prueba[['ccaa', 'producto', 'volumen_miles_de_kg', 'valor_miles_de_€', 'precio_medio_kg', 'date']]\n",
    "sample_model_dict = {product: {comunidad: prueba_model[(prueba_model.producto.eq(product))&\n",
    "                                                      (prueba_model.ccaa.eq(comunidad))].drop(['producto', 'ccaa'], axis = 1)\n",
    "                              for comunidad in prueba_model.ccaa.unique()} for product in prueba_model.producto.unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wrong-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = d = q = range(0, 3)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mounted-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_sarima(variable, model_dict):\n",
    "    min_error_df = pd.DataFrame(columns = ['comunidad', 'producto', 'error'])\n",
    "    try:\n",
    "        len(predicciones)\n",
    "    except NameError:\n",
    "        predicciones = pd.DataFrame(columns = ['ccaa', 'producto'])\n",
    "    vuelta_general = 1\n",
    "    fila_df = 0\n",
    "    for producto, v in model_dict.items():\n",
    "        n_comunidad = 1\n",
    "        for comunidad in v.keys():\n",
    "            combinacion = 1\n",
    "            error_dict = {}\n",
    "            timeseries_data = model_dict[producto][comunidad][[variable, 'date']].copy()\n",
    "            timeseries_data.index = pd.DatetimeIndex(timeseries_data.date)\n",
    "            timeseries_data.drop('date', axis = 1, inplace = True)\n",
    "            timeseries_data.sort_index(inplace = True)\n",
    "\n",
    "            train = timeseries_data.loc[timeseries_data.index <= '2020-02-01']\n",
    "            test = timeseries_data.loc[timeseries_data.index > '2020-02-01']\n",
    "            \n",
    "            for param in pdq:\n",
    "                for seasonal_param in seasonal_pdq:\n",
    "                    print('Tienes', len(model_dict), 'productos y vas por el', vuelta_general, '. Este producto tiene', \n",
    "                          len(v), 'comunidades y vas por la', n_comunidad, 'Hay un total de', len(pdq) * len(seasonal_pdq), \n",
    "                          'combinaciones y vas por la', combinacion, '. La variable es', variable)\n",
    "                    try:\n",
    "                        print(param, seasonal_param)\n",
    "                        mod = SARIMAX(train, \n",
    "                            order = param,\n",
    "                            seasonal_order = seasonal_param, \n",
    "                            enforce_stationarity = False,\n",
    "                            enforce_invertibility = False)                \n",
    "                        result = mod.fit()\n",
    "                        ypred = result.get_forecast(steps = len(test)).predicted_mean.values\n",
    "                        error = rmse(test.values, ypred)\n",
    "                        error_dict.update({error: [param, seasonal_param]})\n",
    "                    except IndexError:\n",
    "                        continue\n",
    "                    combinacion += 1\n",
    "                    clear_output(wait = True)\n",
    "                    \n",
    "            min_error = min(list(error_dict.keys()))\n",
    "            min_error_df.loc[fila_df, ['comunidad', 'producto', 'error']] = comunidad, producto, min_error\n",
    "            final_model = SARIMAX(train, order = error_dict[min_error][0], seasonal_order = error_dict[min_error][1], \n",
    "                                  enforce_stationarity = False, enforce_invertibilty = False)\n",
    "            final_result = final_model.fit()\n",
    "            final_ypred = final_result.get_forecast(steps = len(test))\n",
    "            ypred_df = pd.DataFrame(final_ypred.predicted_mean).rename(columns = {'predicted_mean': str(variable) + '_predicted'})\n",
    "            pred_ci = final_ypred.conf_int()\n",
    "            pred_ci_df = pd.concat([ypred_df, pred_ci], axis = 1)\n",
    "            pred_ci_df[['ccaa', 'producto']] = comunidad, producto\n",
    "            \n",
    "            line = pd.to_datetime('2020-02-01', format = '%Y-%m-%d')\n",
    "            real_value = train.loc[line].values[0]\n",
    "            new_row =  pd.DataFrame({'ccaa': comunidad, 'producto': producto, (variable + '_predicted'): real_value, \n",
    "                         ('lower ' + variable):real_value, ('upper ' + variable): real_value}, \n",
    "                                    index = [line])\n",
    "            predicciones = pd.concat([predicciones, new_row, pred_ci_df], axis = 0)\n",
    "            n_comunidad += 1\n",
    "            fila_df += 1\n",
    "        vuelta_general += 1\n",
    "    return predicciones, min_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intimate-bankruptcy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tienes 50 productos y vas por el 50 . Este producto tiene 18 comunidades y vas por la 18 Hay un total de 729 combinaciones y vas por la 649 . La variable es volumen_miles_de_kg\n"
     ]
    }
   ],
   "source": [
    "df_peque, error_peque = best_sarima('volumen_miles_de_kg', cmpl_model_dict)\n",
    "\n",
    "with open('df_peque.pkl', 'wb') as fp:\n",
    "    pickle.dump(df_peque, fp)    \n",
    "with open('error_peque.pkl', 'wb') as fp:\n",
    "    pickle.dump(error_peque, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hazardous-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_peque.pkl', 'rb') as fp:\n",
    "    df_peque = pickle.load(fp)\n",
    "with open('error_peque.pkl', 'rb') as fp:\n",
    "    error_peque = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peque2, error_peque2 = best_sarima('valor_miles_de_€', cmpl_model_dict)\n",
    "df_medi = pd.concat([df_peque, df_peque2], axis = 1)\n",
    "error_medi = pd.concat([error_peque, error_peque2], axis = 1)\n",
    "with open('df_medi.pkl', 'wb') as fp:\n",
    "    pickle.dump(df_medi, fp)    \n",
    "with open('error_medi.pkl', 'wb') as fp:\n",
    "    pickle.dump(error_medi, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sublime-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_medi.pkl', 'rb') as fp:\n",
    "    df_medi = pickle.load(fp)\n",
    "with open('error_medi.pkl', 'rb') as fp:\n",
    "    error_medi = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "authentic-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_peque3, error_peque3 = best_sarima('precio_medio_kg', cmpl_model_dict)\n",
    "df_gran = pd.concat([df_medi, df_peque3], axis = 1)\n",
    "error_gran = pd.concat([error_medi, error_peque3], axis = 1)\n",
    "with open('df_gran.pkl', 'wb') as fp:\n",
    "    pickle.dump(df_gran, fp)    \n",
    "with open('error_gran.pkl', 'wb') as fp:\n",
    "    pickle.dump(error_gran, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fundamental-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_gran.pkl', 'rb') as fp:\n",
    "    df_gran = pickle.load(fp)\n",
    "with open('error_gran.pkl', 'rb') as fp:\n",
    "    error_gran = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "temporal-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_gran.T.drop_duplicates().T\n",
    "df_final = df_final.loc[:, 'producto':]\n",
    "df_final.to_csv(os.path.join(dir_out, 'predicciones_consumo.csv'), sep = ';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
